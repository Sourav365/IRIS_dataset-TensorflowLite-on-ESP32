# -*- coding: utf-8 -*-
"""IRIS_dataset_Arduino.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1CvxI0Y_tvusdL7Ha0rjqRwXWxacVkYJk
"""

# Commented out IPython magic to ensure Python compatibility.
# %tensorflow_version 2.4.1

# import necessary python packages
import tensorflow as tf
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

tflite_model_name = 'iris'
c_model_name = 'iris'

# Load data
from sklearn.datasets import load_iris
iris = load_iris()

x = iris['data']
y = iris['target']
names = iris['target_names']
feature_names = iris['feature_names']

print(x)
print(y)

# ONE-HOT encoding
from sklearn.preprocessing import OneHotEncoder, StandardScaler
enc = OneHotEncoder()
Y = enc.fit_transform(y[:, np.newaxis]).toarray()
print(Y)

# Normalization
scaler = StandardScaler()
X = scaler.fit_transform(x)
print(X[0])

# Divide the data into train and test set (70:30)
from sklearn.model_selection import train_test_split
X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.3, random_state=42)

print(X_train.shape)
print(Y_train.shape)

print(X_test.shape)
print(Y_test.shape)

num_classes = Y.shape[1]
num_features = X.shape[1]
num_classes

# Model building
from keras.models import Sequential
from keras.layers import Dense
model = Sequential()

# 1st hidden layer
model.add(Dense(5, input_dim=num_features, activation = 'relu'))   # 4*5 +5 = 25
# Output Layer
model.add(Dense(num_classes, activation='softmax'))   # 5*3 + 3 = 18
model.summary()

# Compilation
model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer = 'adam')

# Train model
model.fit(X_train, Y_train, epochs=100, batch_size=100, validation_data=(X, Y))

(loss,accuracy)=model.evaluate(X_test,Y_test, batch_size=10,verbose=1)
accuracy*100

new_data = [5.4, 3, 4.5,1.5]
new_data2 = np.reshape(new_data, (1,4))
Y_pred = np.argmax(model.predict(new_data2))
print(Y_pred)

# Convert Keras model to a tflite model

converter = tf.lite.TFLiteConverter.from_keras_model(model)
tflite_model = converter.convert()

# Save the model to disk
open(tflite_model_name + '.tflite', "wb").write(tflite_model)

# Function: Convert some hex value into an array for C programming
def hex_to_c_array(hex_data, var_name):

  c_str = ''

  # Create header guard
  c_str += '#ifndef ' + var_name.upper() + '_H\n'
  c_str += '#define ' + var_name.upper() + '_H\n\n'

  # Add array length at top of file
  c_str += '\nunsigned int ' + var_name + '_len = ' + str(len(hex_data)) + ';\n'

  # Declare C variable
  c_str += 'unsigned char ' + var_name + '[] = {'
  hex_array = []
  for i, val in enumerate(hex_data) :

    # Construct string from hex
    hex_str = format(val, '#04x')

    # Add formatting so each line stays within 80 characters
    if (i + 1) < len(hex_data):
      hex_str += ','
    if (i + 1) % 12 == 0:
      hex_str += '\n '
    hex_array.append(hex_str)

  # Add closing brace
  c_str += '\n ' + format(' '.join(hex_array)) + '\n};\n\n'

  # Close out header guard
  c_str += '#endif //' + var_name.upper() + '_H'

  return c_str

# Write TFLite model to a C source (or header) file
with open(c_model_name + '.h', 'w') as file:
  file.write(hex_to_c_array(tflite_model, c_model_name))

cfile = open(c_model_name + '.h')
cfile.read()

